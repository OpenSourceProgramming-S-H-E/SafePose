{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1319908d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.19.0-cp39-cp39-win_amd64.whl.metadata (4.1 kB)\n",
      "Collecting tensorflow-hub\n",
      "  Downloading tensorflow_hub-0.16.1-py2.py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow)\n",
      "  Downloading absl_py-2.3.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow)\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=24.3.25 (from tensorflow)\n",
      "  Downloading flatbuffers-25.2.10-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow)\n",
      "  Downloading gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow)\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting libclang>=13.0.0 (from tensorflow)\n",
      "  Downloading libclang-18.1.1-py2.py3-none-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow)\n",
      "  Downloading opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\asus\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow) (25.0)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 (from tensorflow)\n",
      "  Downloading protobuf-5.29.5-cp39-cp39-win_amd64.whl.metadata (592 bytes)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\asus\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow) (58.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow) (1.17.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow)\n",
      "  Downloading termcolor-3.1.0-py3-none-any.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\asus\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tensorflow) (4.14.0)\n",
      "Collecting wrapt>=1.11.0 (from tensorflow)\n",
      "  Downloading wrapt-1.17.2-cp39-cp39-win_amd64.whl.metadata (6.5 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow)\n",
      "  Downloading grpcio-1.72.1-cp39-cp39-win_amd64.whl.metadata (4.0 kB)\n",
      "Collecting tensorboard~=2.19.0 (from tensorflow)\n",
      "  Downloading tensorboard-2.19.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting keras>=3.5.0 (from tensorflow)\n",
      "  Downloading keras-3.10.0-py3-none-any.whl.metadata (6.0 kB)\n",
      "Collecting numpy<2.2.0,>=1.26.0 (from tensorflow)\n",
      "  Downloading numpy-2.0.2-cp39-cp39-win_amd64.whl.metadata (59 kB)\n",
      "Collecting h5py>=3.11.0 (from tensorflow)\n",
      "  Downloading h5py-3.13.0-cp39-cp39-win_amd64.whl.metadata (2.5 kB)\n",
      "Collecting ml-dtypes<1.0.0,>=0.5.1 (from tensorflow)\n",
      "  Downloading ml_dtypes-0.5.1-cp39-cp39-win_amd64.whl.metadata (22 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow)\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.31.0-cp39-cp39-win_amd64.whl.metadata (14 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\asus\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\asus\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\asus\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\asus\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2025.4.26)\n",
      "Collecting markdown>=2.6.8 (from tensorboard~=2.19.0->tensorflow)\n",
      "  Downloading markdown-3.8-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard~=2.19.0->tensorflow)\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard~=2.19.0->tensorflow)\n",
      "  Downloading werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting tf-keras>=2.14.1 (from tensorflow-hub)\n",
      "  Downloading tf_keras-2.19.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting wheel<1.0,>=0.23.0 (from astunparse>=1.6.0->tensorflow)\n",
      "  Downloading wheel-0.45.1-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting rich (from keras>=3.5.0->tensorflow)\n",
      "  Downloading rich-14.0.0-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting namex (from keras>=3.5.0->tensorflow)\n",
      "  Downloading namex-0.1.0-py3-none-any.whl.metadata (322 bytes)\n",
      "Collecting optree (from keras>=3.5.0->tensorflow)\n",
      "  Downloading optree-0.16.0-cp39-cp39-win_amd64.whl.metadata (31 kB)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\asus\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from markdown>=2.6.8->tensorboard~=2.19.0->tensorflow) (8.7.0)\n",
      "Requirement already satisfied: zipp>=3.20 in c:\\users\\asus\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.19.0->tensorflow) (3.22.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\asus\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.2)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich->keras>=3.5.0->tensorflow)\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow)\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Downloading tensorflow-2.19.0-cp39-cp39-win_amd64.whl (375.7 MB)\n",
      "   ---------------------------------------- 0.0/375.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/375.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.5/375.7 MB 2.1 MB/s eta 0:02:59\n",
      "   ---------------------------------------- 0.8/375.7 MB 1.5 MB/s eta 0:04:17\n",
      "   ---------------------------------------- 1.0/375.7 MB 1.4 MB/s eta 0:04:21\n",
      "   ---------------------------------------- 1.6/375.7 MB 1.7 MB/s eta 0:03:43\n",
      "   ---------------------------------------- 2.1/375.7 MB 2.0 MB/s eta 0:03:11\n",
      "   ---------------------------------------- 2.4/375.7 MB 1.9 MB/s eta 0:03:18\n",
      "   ---------------------------------------- 2.6/375.7 MB 1.8 MB/s eta 0:03:26\n",
      "   ---------------------------------------- 2.9/375.7 MB 1.7 MB/s eta 0:03:36\n",
      "   ---------------------------------------- 3.4/375.7 MB 1.7 MB/s eta 0:03:37\n",
      "   ---------------------------------------- 4.2/375.7 MB 2.0 MB/s eta 0:03:11\n",
      "    --------------------------------------- 5.5/375.7 MB 2.3 MB/s eta 0:02:42\n",
      "    --------------------------------------- 7.1/375.7 MB 2.7 MB/s eta 0:02:16\n",
      "    --------------------------------------- 7.9/375.7 MB 2.8 MB/s eta 0:02:11\n",
      "   - -------------------------------------- 10.0/375.7 MB 3.3 MB/s eta 0:01:51\n",
      "   - -------------------------------------- 12.6/375.7 MB 3.9 MB/s eta 0:01:33\n",
      "   - -------------------------------------- 13.9/375.7 MB 4.1 MB/s eta 0:01:30\n",
      "   - -------------------------------------- 16.8/375.7 MB 4.6 MB/s eta 0:01:19\n",
      "   -- ------------------------------------- 20.7/375.7 MB 5.4 MB/s eta 0:01:06\n",
      "   -- ------------------------------------- 22.8/375.7 MB 5.7 MB/s eta 0:01:02\n",
      "   -- ------------------------------------- 24.1/375.7 MB 5.7 MB/s eta 0:01:03\n",
      "   -- ------------------------------------- 26.5/375.7 MB 5.9 MB/s eta 0:01:00\n",
      "   --- ------------------------------------ 29.6/375.7 MB 6.3 MB/s eta 0:00:55\n",
      "   --- ------------------------------------ 34.3/375.7 MB 7.0 MB/s eta 0:00:49\n",
      "   ---- ----------------------------------- 38.0/375.7 MB 7.4 MB/s eta 0:00:46\n",
      "   ---- ----------------------------------- 43.0/375.7 MB 8.1 MB/s eta 0:00:42\n",
      "   ----- ---------------------------------- 47.7/375.7 MB 8.6 MB/s eta 0:00:39\n",
      "   ----- ---------------------------------- 53.2/375.7 MB 9.3 MB/s eta 0:00:35\n",
      "   ------ --------------------------------- 59.0/375.7 MB 9.9 MB/s eta 0:00:33\n",
      "   ------ --------------------------------- 64.2/375.7 MB 10.4 MB/s eta 0:00:30\n",
      "   ------- -------------------------------- 71.8/375.7 MB 11.2 MB/s eta 0:00:28\n",
      "   -------- ------------------------------- 78.4/375.7 MB 11.8 MB/s eta 0:00:26\n",
      "   --------- ------------------------------ 85.2/375.7 MB 12.5 MB/s eta 0:00:24\n",
      "   --------- ------------------------------ 92.3/375.7 MB 13.1 MB/s eta 0:00:22\n",
      "   ---------- ----------------------------- 99.9/375.7 MB 13.8 MB/s eta 0:00:21\n",
      "   ----------- --------------------------- 107.7/375.7 MB 14.4 MB/s eta 0:00:19\n",
      "   ----------- --------------------------- 114.8/375.7 MB 14.9 MB/s eta 0:00:18\n",
      "   ------------ -------------------------- 122.7/375.7 MB 15.5 MB/s eta 0:00:17\n",
      "   ------------- ------------------------- 130.5/375.7 MB 16.1 MB/s eta 0:00:16\n",
      "   -------------- ------------------------ 135.8/375.7 MB 16.3 MB/s eta 0:00:15\n",
      "   -------------- ------------------------ 142.6/375.7 MB 16.7 MB/s eta 0:00:14\n",
      "   --------------- ----------------------- 151.3/375.7 MB 17.3 MB/s eta 0:00:13\n",
      "   ---------------- ---------------------- 157.8/375.7 MB 17.6 MB/s eta 0:00:13\n",
      "   ----------------- --------------------- 165.7/375.7 MB 18.1 MB/s eta 0:00:12\n",
      "   ------------------ -------------------- 174.1/375.7 MB 18.5 MB/s eta 0:00:11\n",
      "   ------------------ -------------------- 181.9/375.7 MB 18.9 MB/s eta 0:00:11\n",
      "   ------------------- ------------------- 190.6/375.7 MB 19.4 MB/s eta 0:00:10\n",
      "   -------------------- ------------------ 197.7/375.7 MB 19.6 MB/s eta 0:00:10\n",
      "   --------------------- ----------------- 206.0/375.7 MB 20.1 MB/s eta 0:00:09\n",
      "   ---------------------- ---------------- 212.9/375.7 MB 20.3 MB/s eta 0:00:09\n",
      "   ---------------------- ---------------- 219.9/375.7 MB 20.6 MB/s eta 0:00:08\n",
      "   ----------------------- --------------- 226.5/375.7 MB 20.8 MB/s eta 0:00:08\n",
      "   ------------------------ -------------- 233.0/375.7 MB 21.0 MB/s eta 0:00:07\n",
      "   ------------------------ -------------- 237.0/375.7 MB 20.9 MB/s eta 0:00:07\n",
      "   ------------------------- ------------- 244.3/375.7 MB 21.2 MB/s eta 0:00:07\n",
      "   -------------------------- ------------ 253.2/375.7 MB 21.5 MB/s eta 0:00:06\n",
      "   --------------------------- ----------- 261.6/375.7 MB 21.9 MB/s eta 0:00:06\n",
      "   --------------------------- ----------- 268.4/375.7 MB 26.9 MB/s eta 0:00:04\n",
      "   ---------------------------- ---------- 275.5/375.7 MB 29.1 MB/s eta 0:00:04\n",
      "   ----------------------------- --------- 281.8/375.7 MB 29.6 MB/s eta 0:00:04\n",
      "   ------------------------------ -------- 289.9/375.7 MB 31.8 MB/s eta 0:00:03\n",
      "   ------------------------------ -------- 297.5/375.7 MB 32.4 MB/s eta 0:00:03\n",
      "   ------------------------------- ------- 305.1/375.7 MB 33.1 MB/s eta 0:00:03\n",
      "   -------------------------------- ------ 313.5/375.7 MB 33.6 MB/s eta 0:00:02\n",
      "   --------------------------------- ----- 319.6/375.7 MB 33.7 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 327.7/375.7 MB 34.1 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 335.0/375.7 MB 34.1 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 342.6/375.7 MB 34.3 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 350.5/375.7 MB 34.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 358.1/375.7 MB 34.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 366.0/375.7 MB 34.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  372.5/375.7 MB 34.3 MB/s eta 0:00:01\n",
      "   --------------------------------------  373.3/375.7 MB 33.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  373.8/375.7 MB 32.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  375.7/375.7 MB 32.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  375.7/375.7 MB 32.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  375.7/375.7 MB 32.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  375.7/375.7 MB 32.5 MB/s eta 0:00:01\n",
      "   --------------------------------------- 375.7/375.7 MB 29.3 MB/s eta 0:00:00\n",
      "Downloading grpcio-1.72.1-cp39-cp39-win_amd64.whl (4.2 MB)\n",
      "   ---------------------------------------- 0.0/4.2 MB ? eta -:--:--\n",
      "   ------------------------------------- -- 3.9/4.2 MB 18.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 4.2/4.2 MB 15.9 MB/s eta 0:00:00\n",
      "Downloading ml_dtypes-0.5.1-cp39-cp39-win_amd64.whl (209 kB)\n",
      "Downloading numpy-2.0.2-cp39-cp39-win_amd64.whl (15.9 MB)\n",
      "   ---------------------------------------- 0.0/15.9 MB ? eta -:--:--\n",
      "   ------------- -------------------------- 5.5/15.9 MB 30.7 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 10.5/15.9 MB 26.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  15.7/15.9 MB 29.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 15.9/15.9 MB 25.7 MB/s eta 0:00:00\n",
      "Downloading protobuf-5.29.5-cp39-cp39-win_amd64.whl (434 kB)\n",
      "Downloading tensorboard-2.19.0-py3-none-any.whl (5.5 MB)\n",
      "   ---------------------------------------- 0.0/5.5 MB ? eta -:--:--\n",
      "   -------------------------------------- - 5.2/5.5 MB 26.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 5.5/5.5 MB 23.9 MB/s eta 0:00:00\n",
      "Downloading tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Downloading tensorflow_hub-0.16.1-py2.py3-none-any.whl (30 kB)\n",
      "Downloading absl_py-2.3.0-py3-none-any.whl (135 kB)\n",
      "Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Downloading wheel-0.45.1-py3-none-any.whl (72 kB)\n",
      "Downloading flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
      "Downloading gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Downloading h5py-3.13.0-cp39-cp39-win_amd64.whl (3.0 MB)\n",
      "   ---------------------------------------- 0.0/3.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 3.0/3.0 MB 15.8 MB/s eta 0:00:00\n",
      "Downloading keras-3.10.0-py3-none-any.whl (1.4 MB)\n",
      "   ---------------------------------------- 0.0/1.4 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.4/1.4 MB 8.9 MB/s eta 0:00:00\n",
      "Downloading libclang-18.1.1-py2.py3-none-win_amd64.whl (26.4 MB)\n",
      "   ---------------------------------------- 0.0/26.4 MB ? eta -:--:--\n",
      "   -------- ------------------------------- 5.8/26.4 MB 32.2 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 10.0/26.4 MB 24.9 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 16.8/26.4 MB 27.1 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 24.6/26.4 MB 29.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 26.4/26.4 MB 25.8 MB/s eta 0:00:00\n",
      "Downloading markdown-3.8-py3-none-any.whl (106 kB)\n",
      "Downloading opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "Downloading tensorflow_io_gcs_filesystem-0.31.0-cp39-cp39-win_amd64.whl (1.5 MB)\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.5/1.5 MB 26.0 MB/s eta 0:00:00\n",
      "Downloading termcolor-3.1.0-py3-none-any.whl (7.7 kB)\n",
      "Downloading tf_keras-2.19.0-py3-none-any.whl (1.7 MB)\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.7/1.7 MB 15.6 MB/s eta 0:00:00\n",
      "Downloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
      "Downloading wrapt-1.17.2-cp39-cp39-win_amd64.whl (38 kB)\n",
      "Downloading namex-0.1.0-py3-none-any.whl (5.9 kB)\n",
      "Downloading optree-0.16.0-cp39-cp39-win_amd64.whl (300 kB)\n",
      "Downloading rich-14.0.0-py3-none-any.whl (243 kB)\n",
      "Downloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: namex, libclang, flatbuffers, wrapt, wheel, werkzeug, termcolor, tensorflow-io-gcs-filesystem, tensorboard-data-server, protobuf, optree, opt-einsum, numpy, mdurl, grpcio, google-pasta, gast, absl-py, ml-dtypes, markdown-it-py, markdown, h5py, astunparse, tensorboard, rich, keras, tensorflow, tf-keras, tensorflow-hub\n",
      "\n",
      "   - --------------------------------------  1/29 [libclang]\n",
      "   - --------------------------------------  1/29 [libclang]\n",
      "   - --------------------------------------  1/29 [libclang]\n",
      "   - --------------------------------------  1/29 [libclang]\n",
      "   ---- -----------------------------------  3/29 [wrapt]\n",
      "   ----- ----------------------------------  4/29 [wheel]\n",
      "   ------ ---------------------------------  5/29 [werkzeug]\n",
      "   ------ ---------------------------------  5/29 [werkzeug]\n",
      "   --------- -----------------------------  7/29 [tensorflow-io-gcs-filesystem]\n",
      "   ------------ ---------------------------  9/29 [protobuf]\n",
      "   ------------ ---------------------------  9/29 [protobuf]\n",
      "   ------------ ---------------------------  9/29 [protobuf]\n",
      "   ------------- -------------------------- 10/29 [optree]\n",
      "   --------------- ------------------------ 11/29 [opt-einsum]\n",
      "   ---------------- ----------------------- 12/29 [numpy]\n",
      "   ---------------- ----------------------- 12/29 [numpy]\n",
      "   ---------------- ----------------------- 12/29 [numpy]\n",
      "   ---------------- ----------------------- 12/29 [numpy]\n",
      "   ---------------- ----------------------- 12/29 [numpy]\n",
      "   ---------------- ----------------------- 12/29 [numpy]\n",
      "   ---------------- ----------------------- 12/29 [numpy]\n",
      "   ---------------- ----------------------- 12/29 [numpy]\n",
      "   ---------------- ----------------------- 12/29 [numpy]\n",
      "   ---------------- ----------------------- 12/29 [numpy]\n",
      "   ---------------- ----------------------- 12/29 [numpy]\n",
      "   ---------------- ----------------------- 12/29 [numpy]\n",
      "   ---------------- ----------------------- 12/29 [numpy]\n",
      "   ---------------- ----------------------- 12/29 [numpy]\n",
      "   ---------------- ----------------------- 12/29 [numpy]\n",
      "   ---------------- ----------------------- 12/29 [numpy]\n",
      "   ---------------- ----------------------- 12/29 [numpy]\n",
      "   ---------------- ----------------------- 12/29 [numpy]\n",
      "   ---------------- ----------------------- 12/29 [numpy]\n",
      "   ---------------- ----------------------- 12/29 [numpy]\n",
      "   ---------------- ----------------------- 12/29 [numpy]\n",
      "   ---------------- ----------------------- 12/29 [numpy]\n",
      "   ---------------- ----------------------- 12/29 [numpy]\n",
      "   ---------------- ----------------------- 12/29 [numpy]\n",
      "   ---------------- ----------------------- 12/29 [numpy]\n",
      "   ---------------- ----------------------- 12/29 [numpy]\n",
      "   ---------------- ----------------------- 12/29 [numpy]\n",
      "   ---------------- ----------------------- 12/29 [numpy]\n",
      "   ---------------- ----------------------- 12/29 [numpy]\n",
      "   ---------------- ----------------------- 12/29 [numpy]\n",
      "   ---------------- ----------------------- 12/29 [numpy]\n",
      "   ------------------- -------------------- 14/29 [grpcio]\n",
      "   ------------------- -------------------- 14/29 [grpcio]\n",
      "   ------------------- -------------------- 14/29 [grpcio]\n",
      "   -------------------- ------------------- 15/29 [google-pasta]\n",
      "   ---------------------- ----------------- 16/29 [gast]\n",
      "   ----------------------- ---------------- 17/29 [absl-py]\n",
      "   -------------------------- ------------- 19/29 [markdown-it-py]\n",
      "   -------------------------- ------------- 19/29 [markdown-it-py]\n",
      "   --------------------------- ------------ 20/29 [markdown]\n",
      "   --------------------------- ------------ 20/29 [markdown]\n",
      "   ---------------------------- ----------- 21/29 [h5py]\n",
      "   ---------------------------- ----------- 21/29 [h5py]\n",
      "   ---------------------------- ----------- 21/29 [h5py]\n",
      "   ------------------------------- -------- 23/29 [tensorboard]\n",
      "   ------------------------------- -------- 23/29 [tensorboard]\n",
      "   ------------------------------- -------- 23/29 [tensorboard]\n",
      "   ------------------------------- -------- 23/29 [tensorboard]\n",
      "   ------------------------------- -------- 23/29 [tensorboard]\n",
      "   ------------------------------- -------- 23/29 [tensorboard]\n",
      "   ------------------------------- -------- 23/29 [tensorboard]\n",
      "   ------------------------------- -------- 23/29 [tensorboard]\n",
      "   ------------------------------- -------- 23/29 [tensorboard]\n",
      "   ------------------------------- -------- 23/29 [tensorboard]\n",
      "   --------------------------------- ------ 24/29 [rich]\n",
      "   --------------------------------- ------ 24/29 [rich]\n",
      "   --------------------------------- ------ 24/29 [rich]\n",
      "   ---------------------------------- ----- 25/29 [keras]\n",
      "   ---------------------------------- ----- 25/29 [keras]\n",
      "   ---------------------------------- ----- 25/29 [keras]\n",
      "   ---------------------------------- ----- 25/29 [keras]\n",
      "   ---------------------------------- ----- 25/29 [keras]\n",
      "   ---------------------------------- ----- 25/29 [keras]\n",
      "   ---------------------------------- ----- 25/29 [keras]\n",
      "   ---------------------------------- ----- 25/29 [keras]\n",
      "   ---------------------------------- ----- 25/29 [keras]\n",
      "   ---------------------------------- ----- 25/29 [keras]\n",
      "   ---------------------------------- ----- 25/29 [keras]\n",
      "   ---------------------------------- ----- 25/29 [keras]\n",
      "   ---------------------------------- ----- 25/29 [keras]\n",
      "   ---------------------------------- ----- 25/29 [keras]\n",
      "   ---------------------------------- ----- 25/29 [keras]\n",
      "   ---------------------------------- ----- 25/29 [keras]\n",
      "   ---------------------------------- ----- 25/29 [keras]\n",
      "   ---------------------------------- ----- 25/29 [keras]\n",
      "   ---------------------------------- ----- 25/29 [keras]\n",
      "   ---------------------------------- ----- 25/29 [keras]\n",
      "   ---------------------------------- ----- 25/29 [keras]\n",
      "   ---------------------------------- ----- 25/29 [keras]\n",
      "   ---------------------------------- ----- 25/29 [keras]\n",
      "   ---------------------------------- ----- 25/29 [keras]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ----------------------------------- ---- 26/29 [tensorflow]\n",
      "   ------------------------------------- -- 27/29 [tf-keras]\n",
      "   ------------------------------------- -- 27/29 [tf-keras]\n",
      "   ------------------------------------- -- 27/29 [tf-keras]\n",
      "   ------------------------------------- -- 27/29 [tf-keras]\n",
      "   ------------------------------------- -- 27/29 [tf-keras]\n",
      "   ------------------------------------- -- 27/29 [tf-keras]\n",
      "   ------------------------------------- -- 27/29 [tf-keras]\n",
      "   ------------------------------------- -- 27/29 [tf-keras]\n",
      "   ------------------------------------- -- 27/29 [tf-keras]\n",
      "   ------------------------------------- -- 27/29 [tf-keras]\n",
      "   ------------------------------------- -- 27/29 [tf-keras]\n",
      "   ------------------------------------- -- 27/29 [tf-keras]\n",
      "   ------------------------------------- -- 27/29 [tf-keras]\n",
      "   ------------------------------------- -- 27/29 [tf-keras]\n",
      "   ------------------------------------- -- 27/29 [tf-keras]\n",
      "   ------------------------------------- -- 27/29 [tf-keras]\n",
      "   ------------------------------------- -- 27/29 [tf-keras]\n",
      "   ------------------------------------- -- 27/29 [tf-keras]\n",
      "   ------------------------------------- -- 27/29 [tf-keras]\n",
      "   ------------------------------------- -- 27/29 [tf-keras]\n",
      "   ------------------------------------- -- 27/29 [tf-keras]\n",
      "   ------------------------------------- -- 27/29 [tf-keras]\n",
      "   ------------------------------------- -- 27/29 [tf-keras]\n",
      "   ------------------------------------- -- 27/29 [tf-keras]\n",
      "   ---------------------------------------- 29/29 [tensorflow-hub]\n",
      "\n",
      "Successfully installed absl-py-2.3.0 astunparse-1.6.3 flatbuffers-25.2.10 gast-0.6.0 google-pasta-0.2.0 grpcio-1.72.1 h5py-3.13.0 keras-3.10.0 libclang-18.1.1 markdown-3.8 markdown-it-py-3.0.0 mdurl-0.1.2 ml-dtypes-0.5.1 namex-0.1.0 numpy-2.0.2 opt-einsum-3.4.0 optree-0.16.0 protobuf-5.29.5 rich-14.0.0 tensorboard-2.19.0 tensorboard-data-server-0.7.2 tensorflow-2.19.0 tensorflow-hub-0.16.1 tensorflow-io-gcs-filesystem-0.31.0 termcolor-3.1.0 tf-keras-2.19.0 werkzeug-3.1.3 wheel-0.45.1 wrapt-1.17.2\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow tensorflow-hub\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d7e043",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow_hub\\resolver.py:120: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow_hub\\resolver.py:120: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow_hub\\module_v2.py:126: The name tf.saved_model.load_v2 is deprecated. Please use tf.compat.v2.saved_model.load instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\tensorflow_hub\\module_v2.py:126: The name tf.saved_model.load_v2 is deprecated. Please use tf.compat.v2.saved_model.load instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "model = hub.load(\"https://tfhub.dev/google/movenet/singlepose/thunder/4\")\n",
    "movenet = model.signatures['serving_default']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4213e180",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcv2\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mload_and_preprocess_image\u001b[39m(image_path):\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def load_and_preprocess_image(image_path):\n",
    "    img = tf.io.read_file(image_path)\n",
    "    img = tf.image.decode_jpeg(img)\n",
    "    img = tf.image.resize_with_pad(img, 256, 256)\n",
    "    input_img = tf.expand_dims(img, axis=0)\n",
    "    input_img = tf.cast(input_img, dtype=tf.int32)\n",
    "    return input_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef4d4fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python\n",
      "  Downloading opencv_python-4.11.0.86-cp37-abi3-win_amd64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\users\\asus\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from opencv-python) (2.0.2)\n",
      "Downloading opencv_python-4.11.0.86-cp37-abi3-win_amd64.whl (39.5 MB)\n",
      "   ---------------------------------------- 0.0/39.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.3/39.5 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 3.1/39.5 MB 13.2 MB/s eta 0:00:03\n",
      "   ------ --------------------------------- 6.8/39.5 MB 15.5 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 12.3/39.5 MB 18.4 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 16.0/39.5 MB 18.3 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 20.7/39.5 MB 19.0 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 25.2/39.5 MB 19.2 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 29.4/39.5 MB 19.2 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 32.0/39.5 MB 18.8 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 34.9/39.5 MB 17.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  38.8/39.5 MB 18.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 39.5/39.5 MB 17.2 MB/s eta 0:00:00\n",
      "Installing collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.11.0.86\n"
     ]
    }
   ],
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731b1a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "882e540a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_image(image_path):\n",
    "    img = tf.io.read_file(image_path)\n",
    "    img = tf.image.decode_jpeg(img)\n",
    "    img = tf.image.resize_with_pad(img, 256, 256)\n",
    "    input_img = tf.expand_dims(img, axis=0)\n",
    "    input_img = tf.cast(input_img, dtype=tf.int32)\n",
    "    return input_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97beed4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_pose(image_path):\n",
    "    input_img = load_and_preprocess_image(image_path)\n",
    "    outputs = movenet(input_img)\n",
    "    keypoints = outputs['output_0'].numpy()\n",
    "    return keypoints[0, 0, :, :2]  # [num_keypoints, (y, x)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2da29a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtensorflow_hub\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mhub\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# 모델 불러오기\u001b[39;00m\n\u001b[0;32m      8\u001b[0m model \u001b[38;5;241m=\u001b[39m hub\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://tfhub.dev/google/movenet/singlepose/thunder/4\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 모델 불러오기\n",
    "model = hub.load(\"https://tfhub.dev/google/movenet/singlepose/thunder/4\")\n",
    "movenet = model.signatures['serving_default']\n",
    "\n",
    "# 이미지 전처리 함수\n",
    "def load_and_preprocess_image(image_path):\n",
    "    img = tf.io.read_file(image_path)\n",
    "    img = tf.image.decode_jpeg(img)\n",
    "    img = tf.image.resize_with_pad(img, 256, 256)\n",
    "    input_img = tf.expand_dims(img, axis=0)\n",
    "    input_img = tf.cast(input_img, dtype=tf.int32)\n",
    "    return input_img\n",
    "\n",
    "# keypoint 추출 함수\n",
    "def detect_pose(image_path):\n",
    "    input_img = load_and_preprocess_image(image_path)\n",
    "    outputs = movenet(input_img)\n",
    "    keypoints = outputs['output_0'].numpy()\n",
    "    return keypoints[0, 0, :, :2]  # [17, (y, x)]\n",
    "\n",
    "# 결과 저장 리스트\n",
    "records = []\n",
    "\n",
    "# Normal 폴더 경로\n",
    "normal_root = './frames/Normal'\n",
    "\n",
    "# normal_01 ~ normal_34 처리 (단, normal_28 제외)\n",
    "for i in range(1, 35):\n",
    "    if i == 28:\n",
    "        continue  # normal_28 제외\n",
    "\n",
    "    folder_name = f'normal_{i:02d}'\n",
    "    folder_path = os.path.join(normal_root, folder_name)\n",
    "\n",
    "    if not os.path.exists(folder_path):\n",
    "        print(f\"[경고] 폴더 없음: {folder_path}\")\n",
    "        continue\n",
    "\n",
    "    for fname in sorted(os.listdir(folder_path)):\n",
    "        if fname.endswith('.jpg') or fname.endswith('.png'):\n",
    "            image_path = os.path.join(folder_path, fname)\n",
    "            keypoints = detect_pose(image_path)\n",
    "\n",
    "            for kp_idx, (y, x) in enumerate(keypoints):\n",
    "                records.append({\n",
    "                    'video_folder': folder_name,\n",
    "                    'frame': fname,\n",
    "                    'keypoint_index': kp_idx,\n",
    "                    'x': float(x),\n",
    "                    'y': float(y)\n",
    "                })\n",
    "\n",
    "# DataFrame으로 변환 및 저장\n",
    "df = pd.DataFrame(records)\n",
    "df.to_csv('keypoints_normal.csv', index=False)\n",
    "print(\"✅ Normal keypoints 저장 완료: keypoints_normal1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b84c66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading pandas-2.2.3-cp39-cp39-win_amd64.whl.metadata (19 kB)\n",
      "Requirement already satisfied: numpy>=1.22.4 in c:\\users\\asus\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas) (2.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\asus\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\asus\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Downloading pandas-2.2.3-cp39-cp39-win_amd64.whl (11.6 MB)\n",
      "   ---------------------------------------- 0.0/11.6 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.3/11.6 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 1.0/11.6 MB 4.2 MB/s eta 0:00:03\n",
      "   -------- ------------------------------- 2.4/11.6 MB 5.0 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 3.7/11.6 MB 5.3 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 4.2/11.6 MB 5.3 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 5.0/11.6 MB 4.4 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 5.8/11.6 MB 4.5 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 6.3/11.6 MB 4.4 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 6.3/11.6 MB 4.4 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 6.8/11.6 MB 3.5 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 7.3/11.6 MB 3.5 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 7.9/11.6 MB 3.3 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 7.9/11.6 MB 3.3 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 8.4/11.6 MB 3.0 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 8.7/11.6 MB 2.9 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 10.2/11.6 MB 3.2 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 10.7/11.6 MB 3.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.6/11.6 MB 3.2 MB/s eta 0:00:00\n",
      "Downloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Downloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Installing collected packages: pytz, tzdata, pandas\n",
      "\n",
      "   ---------------------------------------- 0/3 [pytz]\n",
      "   ---------------------------------------- 0/3 [pytz]\n",
      "   ---------------------------------------- 0/3 [pytz]\n",
      "   ---------------------------------------- 0/3 [pytz]\n",
      "   ---------------------------------------- 0/3 [pytz]\n",
      "   ------------- -------------------------- 1/3 [tzdata]\n",
      "   ------------- -------------------------- 1/3 [tzdata]\n",
      "   ------------- -------------------------- 1/3 [tzdata]\n",
      "   ------------- -------------------------- 1/3 [tzdata]\n",
      "   ------------- -------------------------- 1/3 [tzdata]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   -------------------------- ------------- 2/3 [pandas]\n",
      "   ---------------------------------------- 3/3 [pandas]\n",
      "\n",
      "Successfully installed pandas-2.2.3 pytz-2025.2 tzdata-2025.2\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f34c944",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Normal keypoints 저장 완료: keypoints_normal.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 모델 불러오기\n",
    "model = hub.load(\"https://tfhub.dev/google/movenet/singlepose/thunder/4\")\n",
    "movenet = model.signatures['serving_default']\n",
    "\n",
    "# 이미지 전처리 함수\n",
    "def load_and_preprocess_image(image_path):\n",
    "    img = tf.io.read_file(image_path)\n",
    "    img = tf.image.decode_jpeg(img)\n",
    "    img = tf.image.resize_with_pad(img, 256, 256)\n",
    "    input_img = tf.expand_dims(img, axis=0)\n",
    "    input_img = tf.cast(input_img, dtype=tf.int32)\n",
    "    return input_img\n",
    "\n",
    "# keypoint 추출 함수\n",
    "def detect_pose(image_path):\n",
    "    input_img = load_and_preprocess_image(image_path)\n",
    "    outputs = movenet(input_img)\n",
    "    keypoints = outputs['output_0'].numpy()\n",
    "    return keypoints[0, 0, :, :2]  # [17, (y, x)]\n",
    "\n",
    "# 결과 저장 리스트\n",
    "records = []\n",
    "\n",
    "# Normal 폴더 경로\n",
    "normal_root = 'G:/내 드라이브/Colab Notebooks/FallDetection/frames/Normal'\n",
    "\n",
    "# normal_01 ~ normal_34 처리 (단, normal_28 제외)\n",
    "for i in range(1, 35):\n",
    "    if i == 28:\n",
    "        continue  # normal_28 제외\n",
    "\n",
    "    folder_name = f'normal_{i:02d}'\n",
    "    folder_path = os.path.join(normal_root, folder_name)\n",
    "\n",
    "    if not os.path.exists(folder_path):\n",
    "        print(f\"[경고] 폴더 없음: {folder_path}\")\n",
    "        continue\n",
    "\n",
    "    for fname in sorted(os.listdir(folder_path)):\n",
    "        if fname.endswith('.jpg') or fname.endswith('.png'):\n",
    "            image_path = os.path.join(folder_path, fname)\n",
    "            keypoints = detect_pose(image_path)\n",
    "\n",
    "            for kp_idx, (y, x) in enumerate(keypoints):\n",
    "                records.append({\n",
    "                    'video_folder': folder_name,\n",
    "                    'frame': fname,\n",
    "                    'keypoint_index': kp_idx,\n",
    "                    'x': float(x),\n",
    "                    'y': float(y)\n",
    "                })\n",
    "\n",
    "# DataFrame으로 변환 및 저장\n",
    "df = pd.DataFrame(records)\n",
    "df.to_csv('keypoints_normal.csv', index=False)\n",
    "print(\"✅ Normal keypoints 저장 완료: keypoints_normal.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0491371",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ASUS\\AppData\\Local\\Programs\\Microsoft VS Code\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59ad767",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('G:/내 드라이브/Colab Notebooks/FallDetection/keypoints_normal.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9ade07",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to interrupt the Kernel. \n",
      "\u001b[1;31mNo kernel associated with the notebook. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to interrupt the Kernel. \n",
      "\u001b[1;31mNo kernel associated with the notebook. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to restart the Kernel. \n",
      "\u001b[1;31mNo kernel associated with the notebook. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to interrupt the Kernel. \n",
      "\u001b[1;31mNo kernel associated with the notebook. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to restart the Kernel. \n",
      "\u001b[1;31mNo kernel associated with the notebook. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "fall_root = 'G:/내 드라이브/Colab Notebooks/FallDetection/frames/Fall'\n",
    "records = []\n",
    "\n",
    "for i in range(1, 31):\n",
    "    folder_name = f'fall_{i:02d}'\n",
    "    folder_path = os.path.join(fall_root, folder_name)\n",
    "    if not os.path.exists(folder_path):\n",
    "        print(f\"[❌ 경고] 없음: {folder_path}\")\n",
    "        continue\n",
    "\n",
    "    for fname in sorted(os.listdir(folder_path)):\n",
    "        if fname.endswith('.jpg') or fname.endswith('.png'):\n",
    "            image_path = os.path.join(folder_path, fname)\n",
    "            try:\n",
    "                keypoints = detect_pose(image_path)\n",
    "                for idx, (y, x) in enumerate(keypoints):\n",
    "                    records.append({\n",
    "                        'class': 'Fall',\n",
    "                        'video_folder': folder_name,\n",
    "                        'frame': fname,\n",
    "                        'keypoint_index': idx,\n",
    "                        'x': float(x),\n",
    "                        'y': float(y)\n",
    "                    })\n",
    "            except Exception as e:\n",
    "                print(f\"[⚠️ 오류] {image_path} 실패: {e}\")\n",
    "\n",
    "df = pd.DataFrame(records)\n",
    "df.to_csv('keypoints_fall.csv', index=False)\n",
    "print(\"✅ keypoints_fall.csv 저장 완료\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88781d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import numpy as np\n",
    "\n",
    "# 모델 1회만 로드\n",
    "model = hub.load(\"https://tfhub.dev/google/movenet/singlepose/thunder/4\")\n",
    "movenet = model.signatures['serving_default']\n",
    "\n",
    "# 전처리 및 추론 함수\n",
    "def load_and_preprocess_image(image_path):\n",
    "    img = tf.io.read_file(image_path)\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    img = tf.image.resize_with_pad(img, 256, 256)\n",
    "    input_img = tf.expand_dims(img, axis=0)\n",
    "    input_img = tf.cast(input_img, dtype=tf.int32)\n",
    "    return input_img\n",
    "\n",
    "def detect_pose(image_path):\n",
    "    input_img = load_and_preprocess_image(image_path)\n",
    "    outputs = movenet(input_img)\n",
    "    keypoints = outputs['output_0'].numpy()\n",
    "    return keypoints[0, 0, :, :2]\n",
    "\n",
    "# ✅ 기존 파일 불러오기 (있으면 이어서, 없으면 새로)\n",
    "existing_csv = 'keypoints_fall.csv'\n",
    "processed = set()\n",
    "\n",
    "if os.path.exists(existing_csv):\n",
    "    df_existing = pd.read_csv(existing_csv)\n",
    "    processed = set(zip(df_existing['video_folder'], df_existing['frame']))\n",
    "    print(f\"🔁 이미 처리된 개수: {len(processed)//17}개 프레임\")\n",
    "\n",
    "# 경로 설정 (네 경로로 수정)\n",
    "fall_root = 'G:/내 드라이브/Colab Notebooks/FallDetection/frames/Fall'\n",
    "new_records = []\n",
    "\n",
    "# 이어서 실행\n",
    "for i in range(1, 31):\n",
    "    folder_name = f'fall_{i:02d}'\n",
    "    folder_path = os.path.join(fall_root, folder_name)\n",
    "    if not os.path.exists(folder_path):\n",
    "        print(f\"❌ 폴더 없음: {folder_path}\")\n",
    "        continue\n",
    "\n",
    "    for fname in sorted(os.listdir(folder_path)):\n",
    "        if not (fname.endswith('.jpg') or fname.endswith('.png')):\n",
    "            continue\n",
    "\n",
    "        if (folder_name, fname) in processed:\n",
    "            continue  # 이미 처리된 프레임이면 건너뜀\n",
    "\n",
    "        image_path = os.path.join(folder_path, fname)\n",
    "        try:\n",
    "            keypoints = detect_pose(image_path)\n",
    "            for idx, (y, x) in enumerate(keypoints):\n",
    "                new_records.append({\n",
    "                    'class': 'Fall',\n",
    "                    'video_folder': folder_name,\n",
    "                    'frame': fname,\n",
    "                    'keypoint_index': idx,\n",
    "                    'x': float(x),\n",
    "                    'y': float(y)\n",
    "                })\n",
    "        except Exception as e:\n",
    "            print(f\"[⚠️ 오류] {image_path} 실패: {e}\")\n",
    "\n",
    "# 이어 붙이기 or 새로 저장\n",
    "if os.path.exists(existing_csv):\n",
    "    df_all = pd.concat([df_existing, pd.DataFrame(new_records)], ignore_index=True)\n",
    "else:\n",
    "    df_all = pd.DataFrame(new_records)\n",
    "\n",
    "df_all.to_csv(existing_csv, index=False)\n",
    "print(\"✅ keypoints_fall.csv 저장 완료 (중단 지점부터 이어서 실행됨)\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
